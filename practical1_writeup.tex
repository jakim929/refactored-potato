\documentclass[11pt]{article}
% \pagestyle{empty}

\usepackage{amssymb}
% \usepackage{times}
% \usepackage{mathptm}

\title{Practical 1: Predicting the Efficiency of Organic Photovoltaics}
\author{Spencer Kim, James Kim, Helen Wu}
\date{\today}

\begin{document}

\maketitle
\section{Technical Approach}
Throughout this process, we used cross validation on 900,000 of the molecules in the given training set and the error we report is from the remaining 100,000.

We started off trying several different models:We tried Lasso regression because we suspected the resulting weight matrix would be sparse (probably not all of the 256 provided features are useful in predicting the HOMO-LUMO gap). We also tried ridge regression and elastic net from sklearn, just in case our continued large error was due to overfitting. However, these yielded results no better than the simple linear regression, so here we decided to try a different approach.

We then moved on to trying bagging and boosting techniques with linear regression, attempting to decrease variance in the models and potentially decrease generalized error. However, this did not result in significantly less error when we tested it against the test set. We tried boosting and bagging with many different models, including linear regression, lasso regression (because we suspected that the the resulting weight matrix would be sparse), and ridge regression, but all of them yielded similar error values to linear regression.

For the Lasso Linear regression, we used k-fold cross validation $(k = 5)$ on the training set to choose the model's lambda. For the lasso linear regression with the original feature set, the lambda value we obtained through cross validation was around $8.319 * 10^{-5}$, which caused the loss function to be quite similar to the regular linear regression. For the feature set obtained from 256bit Morgan fingerprinting, the lambda value was around $5.552 * 10^{-5}$, still quite small, making the extra term in the loss function somewhat meaningless. This is probably what cause the lasso linear regression to yield very similar RMSE test error values to the regular linear regression.

For the Ridge Linear regression, we used k-fold cross validation again to choose the lambda value. The lambda values we tested for are

\[
\lambda = \{ 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0 \}
\]
Using the given 256 features, our ridge regression used a $\lambda = 1.0$ after cross validation, and for the new Morgan fingerprint features (256bit), the model used a $\lambda = 10.0$ after cross validation. However, even so, the RMSE error values stayed quite similar to the regular linear regression.

Because we were not making headway along this vein, we then surmised that perhaps the provided features were not very good at predicting the HOMO-LUMO gap, at least by themselves. We looked into how to extract new features with rdkit. We saw a feature called Morgan fingerprinting which had the possibility of giving us bit vector of whatever size we desired. The default number of bits this yields is 256 per molecule, so we tried this smaller dataset first to determine if this data would yield a better result than the training data that we were given. 

We realized that the new features from Morgan fingerprint algorithm worked significantly better even with simple linear regression than any other method with the given feature, and then we endeavored to find out which model was best for this data by trying out several different models. When we figured out the best model, we increased the number of bits output by Morgan fingerprint to 512 per molecule with plain linear regression (throwing out the original data). This data yielded better results than that we obtained with the original data. So, we then increased the Morgan fingerprint bit vector of 1024 for each molecule with plain linear regression, and this yielded even better results. Following this, we used random forest, and this approach worked yet better.

\section{Results}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Regression type & Feature Set & Validation Error (Test Set)\\
\hline
Linear &Given & 0.30091\\
Random Forest & Given& 0.27460\\
Ridge & Given& 0.30091\\
Lasso &Given& 0.30092\\
Linear&Morgan(256)& 0.21651\\
Ridge&Morgan(256)& 0.21651\\
Lasso&Morgan(256)& 0.21653 \\
Random Forest&Morgan (256)& 0.10412\\
Random Forest&Morgan (512)& 0.08658\\
Random Forest&Morgan (1024)& 0.03117\\
\hline
\end{tabular}
\end{center}

\section{Discussion}
Random forest probably works so well on this data set because it is quick on large data sets, and it is very plausible that similarities in a few of the bits of the Morgan Fingerprint almost completely account for similarities between HOMO-LUMO gap.


\end{document}